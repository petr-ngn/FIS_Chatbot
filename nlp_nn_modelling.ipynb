{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using region Hlavni mesto Praha server backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '10'\n",
    "\n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt', quiet = True)\n",
    "nltk.download(\"wordnet\", quiet = True)\n",
    "nltk.download('stopwords', quiet = True)\n",
    "\n",
    "from src_PN.PN_functions import nlp_nn_modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1998\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------- CS NLP NEURAL NETWORK MODELLING ---------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "STARTING NLP NEURAL NETWORK MODELLING\n",
      "\n",
      "\n",
      "          1. Loading intents\n",
      "          2. Updating intents' responses\n",
      "          3. Text preprocessing and exporting\n",
      "          4. Bayesian Optimization and Neural Network modelling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ngnpe\\anaconda3\\envs\\fis_chatbot\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 266, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\ngnpe\\anaconda3\\envs\\fis_chatbot\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 231, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\ngnpe\\anaconda3\\envs\\fis_chatbot\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "  File \"c:\\Users\\ngnpe\\anaconda3\\envs\\fis_chatbot\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 214, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "  File \"c:\\Users\\ngnpe\\anaconda3\\envs\\fis_chatbot\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 144, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "  File \"c:\\Users\\ngnpe\\anaconda3\\envs\\fis_chatbot\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\ngnpe\\anaconda3\\envs\\fis_chatbot\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.FailedPreconditionError: {{function_node __wrapped__MergeV2Checkpoints_device_/job:localhost/replica:0/task:0/device:CPU:0}} Failed to rename: .\\Bayes_NN_cs\\trial_011\\checkpoint_temp/part-00000-of-00001.data-00000-of-00001 to: .\\Bayes_NN_cs\\trial_011\\checkpoint.data-00000-of-00001 : The process cannot access the file because it is being used by another process.\n",
      "; Broken pipe [Op:MergeV2Checkpoints]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ngnpe\\anaconda3\\envs\\fis_chatbot\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 266, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\ngnpe\\anaconda3\\envs\\fis_chatbot\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 231, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\ngnpe\\anaconda3\\envs\\fis_chatbot\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "  File \"c:\\Users\\ngnpe\\anaconda3\\envs\\fis_chatbot\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 214, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "  File \"c:\\Users\\ngnpe\\anaconda3\\envs\\fis_chatbot\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 144, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "  File \"c:\\Users\\ngnpe\\anaconda3\\envs\\fis_chatbot\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\ngnpe\\anaconda3\\envs\\fis_chatbot\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.FailedPreconditionError: {{function_node __wrapped__MergeV2Checkpoints_device_/job:localhost/replica:0/task:0/device:CPU:0}} Failed to rename: .\\Bayes_NN_cs\\trial_069\\checkpoint_temp/part-00000-of-00001.data-00000-of-00001 to: .\\Bayes_NN_cs\\trial_069\\checkpoint.data-00000-of-00001 : The process cannot access the file because it is being used by another process.\n",
      "; Broken pipe [Op:MergeV2Checkpoints]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Final model hyperparameters' values: \n",
      "\n",
      "                     Dense_layers: 1\n",
      "                     DenseLayer_0: 51\n",
      "                     Activation_0: tanh\n",
      "                     KernelRegularizer_0: 2.175092397337819e-08\n",
      "                     ActivityRegularizer_0: 9.328515889601522e-09\n",
      "                     Dropout_0: 2.3495386767734076e-05\n",
      "                     LearningRate: 0.009264436128630775\n",
      "                     Alpha: 0.03482061632108658\n",
      "                     Gamma: 0.13682289471772455\n",
      "                     DenseLayer_1: 314\n",
      "                     Activation_1: relu\n",
      "                     KernelRegularizer_1: 0.00016999859946450883\n",
      "                     ActivityRegularizer_1: 0.00023764254976249357\n",
      "                     Dropout_1: 0.00019660869130242492\n",
      "                     DenseLayer_2: 305\n",
      "                     Activation_2: relu\n",
      "                     KernelRegularizer_2: 0.007461188369390543\n",
      "                     ActivityRegularizer_2: 9.125143055614066e-09\n",
      "                     Dropout_2: 2.7428217145409203e-06\n",
      "                     DenseLayer_3: 264\n",
      "                     Activation_3: tanh\n",
      "                     KernelRegularizer_3: 9.832544694872557e-10\n",
      "                     ActivityRegularizer_3: 1.0173369922529396e-06\n",
      "                     Dropout_3: 0.0249033230607298\n",
      "                     DenseLayer_4: 234\n",
      "                     Activation_4: tanh\n",
      "                     KernelRegularizer_4: 9.708586522021344e-06\n",
      "                     ActivityRegularizer_4: 9.891254100858182e-05\n",
      "                     Dropout_4: 0.028458079483258545\n",
      "                     DenseLayer_5: 194\n",
      "                     Activation_5: tanh\n",
      "                     KernelRegularizer_5: 0.1484327984304687\n",
      "                     ActivityRegularizer_5: 0.004898918529287826\n",
      "                     Dropout_5: 0.07741773626607425\n",
      "                     DenseLayer_6: 104\n",
      "                     Activation_6: tanh\n",
      "                     KernelRegularizer_6: 0.027778632062980684\n",
      "                     ActivityRegularizer_6: 1.302881996958362e-06\n",
      "                     Dropout_6: 0.24259656714184022\n",
      "                     DenseLayer_7: 309\n",
      "                     Activation_7: tanh\n",
      "                     KernelRegularizer_7: 2.524916673549336e-10\n",
      "                     ActivityRegularizer_7: 3.775192467154877e-05\n",
      "                     Dropout_7: 0.0019394478755784146\n",
      "                     DenseLayer_8: 376\n",
      "                     Activation_8: tanh\n",
      "                     KernelRegularizer_8: 4.1699735942319407e-10\n",
      "                     ActivityRegularizer_8: 1.0190215353859124e-05\n",
      "                     Dropout_8: 0.009221643015814775\n",
      "                     DenseLayer_9: 102\n",
      "                     Activation_9: tanh\n",
      "                     KernelRegularizer_9: 0.014885129549171231\n",
      "                     ActivityRegularizer_9: 6.530047820218384e-08\n",
      "                     Dropout_9: 0.04224495367512851\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          5. Converting the NN model to TFLite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) InputLayer with unsupported characters which will be renamed to inputlayer in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "NLP NEURAL NETWORK MODELLING FINISHED\n"
     ]
    }
   ],
   "source": [
    "nn_model_cs, words_cs, classes_cs, X_train_cs, y_train_cs = nlp_nn_modelling('cs', seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "---------------------------------- EN NLP NEURAL NETWORK MODELLING ---------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "STARTING NLP NEURAL NETWORK MODELLING\n",
      "\n",
      "\n",
      "          1. Loading intents\n",
      "          2. Updating intents' responses\n",
      "          3. Text preprocessing and exporting\n",
      "          4. Bayesian Optimization and Neural Network modelling\n",
      "               Final model hyperparameters' values: \n",
      "\n",
      "                     Dense_layers: 1\n",
      "                     DenseLayer_0: 51\n",
      "                     Activation_0: tanh\n",
      "                     KernelRegularizer_0: 2.175092397337819e-08\n",
      "                     ActivityRegularizer_0: 9.328515889601522e-09\n",
      "                     Dropout_0: 2.3495386767734076e-05\n",
      "                     LearningRate: 0.009264436128630775\n",
      "                     Alpha: 0.03482061632108658\n",
      "                     Gamma: 0.13682289471772455\n",
      "                     DenseLayer_1: 314\n",
      "                     Activation_1: relu\n",
      "                     KernelRegularizer_1: 0.00016999859946450883\n",
      "                     ActivityRegularizer_1: 0.00023764254976249357\n",
      "                     Dropout_1: 0.00019660869130242492\n",
      "                     DenseLayer_2: 305\n",
      "                     Activation_2: relu\n",
      "                     KernelRegularizer_2: 0.007461188369390543\n",
      "                     ActivityRegularizer_2: 9.125143055614066e-09\n",
      "                     Dropout_2: 2.7428217145409203e-06\n",
      "                     DenseLayer_3: 264\n",
      "                     Activation_3: tanh\n",
      "                     KernelRegularizer_3: 9.832544694872557e-10\n",
      "                     ActivityRegularizer_3: 1.0173369922529396e-06\n",
      "                     Dropout_3: 0.0249033230607298\n",
      "                     DenseLayer_4: 234\n",
      "                     Activation_4: tanh\n",
      "                     KernelRegularizer_4: 9.708586522021344e-06\n",
      "                     ActivityRegularizer_4: 9.891254100858182e-05\n",
      "                     Dropout_4: 0.028458079483258545\n",
      "                     DenseLayer_5: 194\n",
      "                     Activation_5: tanh\n",
      "                     KernelRegularizer_5: 0.1484327984304687\n",
      "                     ActivityRegularizer_5: 0.004898918529287826\n",
      "                     Dropout_5: 0.07741773626607425\n",
      "                     DenseLayer_6: 104\n",
      "                     Activation_6: tanh\n",
      "                     KernelRegularizer_6: 0.027778632062980684\n",
      "                     ActivityRegularizer_6: 1.302881996958362e-06\n",
      "                     Dropout_6: 0.24259656714184022\n",
      "                     DenseLayer_7: 309\n",
      "                     Activation_7: tanh\n",
      "                     KernelRegularizer_7: 2.524916673549336e-10\n",
      "                     ActivityRegularizer_7: 3.775192467154877e-05\n",
      "                     Dropout_7: 0.0019394478755784146\n",
      "                     DenseLayer_8: 376\n",
      "                     Activation_8: tanh\n",
      "                     KernelRegularizer_8: 4.1699735942319407e-10\n",
      "                     ActivityRegularizer_8: 1.0190215353859124e-05\n",
      "                     Dropout_8: 0.009221643015814775\n",
      "                     DenseLayer_9: 102\n",
      "                     Activation_9: tanh\n",
      "                     KernelRegularizer_9: 0.014885129549171231\n",
      "                     ActivityRegularizer_9: 6.530047820218384e-08\n",
      "                     Dropout_9: 0.04224495367512851\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          5. Converting the NN model to TFLite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) InputLayer with unsupported characters which will be renamed to inputlayer in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "NLP NEURAL NETWORK MODELLING FINISHED\n"
     ]
    }
   ],
   "source": [
    "nn_model_en, words_en, classes_en, X_train_en, y_train_en = nlp_nn_modelling('en', seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fis_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
